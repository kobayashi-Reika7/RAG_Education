RAG（Retrieval-Augmented Generation）基礎解説
■ RAGとは？

RAG（検索拡張生成）とは、

「外部データを検索（Retrieval）してからLLMが回答生成（Generation）する仕組み」

です。

通常のLLMは「学習済み知識のみ」で回答しますが、
RAGは「検索した最新・社内・独自データ」を参照して回答できます。

■ なぜRAGが必要？

LLM単体の課題：

学習データ以降の情報を知らない

社内文書・PDF・DBの内容は知らない

ハルシネーション（もっともらしい誤答）が起こる

RAGを使うと：

✅ 最新情報を反映
✅ 社内ナレッジ活用
✅ 回答根拠を提示可能
✅ 誤答リスク低減

■ RAGの基本処理フロー

① ユーザー質問
② 質問をベクトル化
③ 類似検索（Vector Search）
④ 関連文書取得
⑤ 文脈付きでLLMへ入力
⑥ 回答生成

■ 構成要素
要素	役割
LLM	回答生成
Embeddingモデル	テキストを数値化
ベクトルDB	類似検索
Retriever	関連文書取得
Prompt	LLMへの指示
■ ベクトル検索とは？

文章を数値ベクトルへ変換し、

「意味の近さ」で検索

する技術。

キーワード一致ではなく、

✔ 意味類似
✔ 言い換え対応
✔ 自然な検索

が可能。

■ チャンク分割の重要性

長文はそのまま保存しない：

❌ 検索精度低下
❌ ノイズ増加

対策：

✅ 適切な長さで分割
✅ 意味単位で区切る

■ ハルシネーション対策

RAGの目的の一つ：

「文脈に基づく回答を強制する」

プロンプト例：

文脈外は禁止

不明時は「分かりません」

根拠提示

✅ ○×問題（True  False）
Q1

RAGはLLMの学習データを書き換える技術である。

答え：❌ ×

解説：
RAGは「学習を書き換えない」。
外部データを検索して追加参照する仕組み。

Q2

RAGを使うと社内文書を参照した回答が可能になる。

答え：⭕ ○

解説：
RAGの最大の利点。
PDF・DB・ナレッジベース活用可能。

Q3

ベクトル検索はキーワード完全一致のみを使う。

答え：❌ ×

解説：
意味類似検索。
「言い換え」「表現違い」に強い。

Q4

チャンク分割は検索精度に影響しない。

答え：❌ ×

解説：
非常に重要。
長すぎ → ノイズ
短すぎ → 文脈不足

Q5

RAGはハルシネーション低減に役立つ。

答え：⭕ ○

解説：
文脈制約＋根拠提示で誤答抑制。

✅ 四択問題（Multiple Choice）
Q6

RAGの「R」は何を意味する？

A. Ranking
B. Retrieval
C. Reasoning
D. Response

答え：✅ B. Retrieval

解説：
Retrieval = 検索・取得

Q7

RAGで類似検索に使われるのは？

A. SQL検索
B. キーワード検索
C. ベクトル検索
D. 画像検索

答え：✅ C. ベクトル検索

解説：
意味的な近さで検索。

Q8

Embeddingモデルの役割は？

A. 回答生成
B. 文書要約
C. テキスト数値化
D. DB保存

答え：✅ C. テキスト数値化

解説：
意味を保持したベクトルへ変換。

Q9

チャンク分割の目的は？

A. LLMの速度低下
B. UI改善
C. 検索精度向上
D. DB容量削減

答え：✅ C. 検索精度向上

解説：
意味単位で検索しやすくする。

Q10

RAGでLLMに渡す情報は？

A. 質問のみ
B. 学習データのみ
C. 文脈＋質問
D. DB接続情報

答え：✅ C. 文脈＋質問

解説：
Retrieved Context + Question

✅ ○×問題（上級編）
Q1

RAGにおいて、Embeddingモデルを変更しても既存ベクトルDBはそのまま利用できる。

答え：❌ ×

解説：
Embeddingモデルを変更するとベクトル空間が変わる。
既存ベクトルとの互換性が崩れるため、

✔ 再Embedding（再インデックス化）
が原則必要。

Q2

類似検索のTop-Kを増やせば、常に回答品質は向上する。

答え：❌ ×

解説：
Top-K過多の問題：

❌ ノイズ増加
❌ 関係ない文脈混入
❌ LLMの注意分散

適切なK選定が重要（通常3〜8程度から調整）。

Q3

RAGの精度問題は、LLMの温度（temperature）調整で解決できる。

答え：❌ ×

解説：
temperatureは生成のランダム性制御。
検索精度には直接関係しない。

精度改善対象：

✔ チャンク設計
✔ Embedding
✔ 検索アルゴリズム
✔ リランキング

Q4

チャンクを小さくすればするほど検索精度は向上する。

答え：❌ ×

解説：

小さすぎる場合：

❌ 文脈不足
❌ 意味切断
❌ 回答不能化

理想：

✔ 意味単位
✔ 文章のまとまり

Q5

ハイブリッド検索（BM25＋ベクトル）はRAG精度向上に有効な戦略である。

答え：⭕ ○

解説：

✔ キーワード一致の強み
✔ 意味類似の強み

両方活用 → 安定性向上。

✅ 四択問題（設計・最適化編）
Q6

RAGで「検索は正しいが回答が不正確」な場合の最優先確認ポイントは？

A. ベクトルDBの容量
B. プロンプト設計
C. temperature
D. APIキー

答え：✅ B. プロンプト設計

解説：

LLMは文脈を渡しても：

❌ 無視
❌ 解釈ミス
❌ 推測

が起こり得る。

✔ 文脈強制
✔ 根拠要求
✔ 推測禁止

の指示が必要。

Q7

検索精度低下の主因として最も影響が大きいものは？

A. UIデザイン
B. チャンク分割設計
C. temperature
D. CSS

答え：✅ B. チャンク分割設計

解説：

RAG品質の土台：

✔ 何を検索対象にするか
✔ どう分割するか

ここで精度の8割が決まることも多い。

Q8

リランキング（Re-ranking）の目的は？

A. DB容量削減
B. LLM高速化
C. 検索結果の順位最適化
D. Embedding削除

答え：✅ C. 検索結果の順位最適化

解説：

初期検索 → 粗い候補
リランキング → 精密選別

✔ Cross-Encoder
✔ LLM-based rerank

Q9

RAGで「関係ない回答」が出る典型原因は？

A. GPU不足
B. 文脈汚染（irrelevant chunks）
C. フォント設定
D. HTML構造

答え：✅ B. 文脈汚染

解説：

不要チャンク混入 →

❌ 誤誘導
❌ ハルシネーション増加

対策：

✔ Top-K調整
✔ スコア閾値
✔ リランキング

Q10

次のうちRAG改善として誤りはどれ？

A. チャンク意味単位化
B. Embedding最適化
C. Top-Kを100に設定
D. プロンプト制約強化

答え：✅ C. Top-Kを100に設定

解説：

Top-K過多 →

❌ ノイズ爆増
❌ Token圧迫
❌ LLM混乱

✅ 超上級（実務トラブル系）
Q11

「検索結果は正しいが毎回回答が揺れる」原因として最も妥当なのは？

A. ベクトル次元不足
B. temperature高すぎ
C. DB破損
D. OCR精度

答え：✅ B. temperature高すぎ

解説：

temperature↑ →

✔ 出力多様化
✔ 表現揺れ
✔ 内容ブレ

安定性重視 → 低温度。

Q12

「RAGで古い情報が回答される」最も典型的な原因は？

A. CSSキャッシュ
B. 最新文書未インデックス
C. LLM性能不足
D. GPU温度

答え：✅ B. 最新文書未インデックス

解説：

✔ 再インデックス忘れ
✔ 更新パイプライン欠如

運用設計ミス。

Q13

RAGでtoken制限に引っかかる主因は？

A. Embeddingモデル
B. 文脈過多
C. ベクトルDB
D. ネットワーク

答え：✅ B. 文脈過多

解説：

✔ Top-K多すぎ
✔ チャンク長すぎ

→ Prompt肥大化。