[
  {
    "chunk_id": "manual_001",
    "section": "はじめに",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "概要",
      "area": "全般",
      "tags": ["RAG", "AI", "教育", "目的", "ゴール"]
    },
    "content": "新人向けRAG/AI基礎マニュアル（詳細版）。本書は、RAGを活用したAI学習アプリを題材として、AIおよびRAGの基礎から実務的な考え方までを理解するための新人向け教材です。専門知識を前提とせず、「仕組みを説明できる」状態をゴールとします。"
  },
  {
    "chunk_id": "manual_002",
    "section": "第1章: AIとLLMの基礎理解",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "基礎知識",
      "area": "AI/LLM",
      "tags": ["AI", "人工知能", "LLM", "大規模言語モデル", "機械学習", "確率予測"]
    },
    "content": "AI（人工知能）とは、人間が行ってきた判断・生成・分類といった知的作業を、コンピュータで実現する技術の総称です。従来のプログラムは、あらかじめ決められたルール通りに処理を行います。一方AIは、大量のデータから傾向を学習します。LLM（大規模言語モデル）は、文章データを学習したAIであり、自然な文章生成や質問応答を得意とします。ただしLLMは意味を理解しているわけではなく、確率的に単語を予測しています。そのため誤情報を出力する場合があります。【章末クイズ】Q1: LLMとは何を学習したAIか説明してください。Q2: AIと従来システムの違いを述べてください。"
  },
  {
    "chunk_id": "manual_003",
    "section": "第2章: RAGが必要になる理由",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "基礎知識",
      "area": "RAG",
      "tags": ["RAG", "LLM", "限界", "正確性", "説明可能性", "更新容易性"]
    },
    "content": "LLM単体では、学習済みの知識しか扱えません。最新情報や社内情報は含まれません。また、LLMは根拠を持たずに回答するため、業務用途ではリスクがあります。RAGは、回答生成前に関連情報を検索し、その情報を元に回答する仕組みです。これにより、正確性・説明可能性・更新容易性が向上します。【章末クイズ】Q1: なぜLLM単体では業務利用が難しいのか説明してください。Q2: RAGの役割を一言で説明してください。"
  },
  {
    "chunk_id": "manual_004",
    "section": "第3章: RAGの基本構造",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "基礎知識",
      "area": "RAG",
      "tags": ["RAG", "Retrieval", "Generation", "検索", "生成", "外部知識"]
    },
    "content": "RAGは検索（Retrieval）と生成（Generation）の2段階で構成されます。まず質問と意味的に近い文章を検索し、次にその文章を参考にLLMが回答を生成します。この仕組みにより、AIは外部知識を参照して回答できます。【章末クイズ】Q1: RetrievalとGenerationの違いを説明してください。"
  },
  {
    "chunk_id": "manual_005",
    "section": "第4章: フロントエンドの役割",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "アプリ構成",
      "area": "フロントエンド",
      "tags": ["フロントエンド", "UI", "入力", "表示", "操作体験"]
    },
    "content": "フロントエンドはユーザーが直接操作する画面部分です。入力受付、結果表示、操作体験を担当します。【章末クイズ】Q1: このアプリにおけるフロントエンドの役割は何ですか？"
  },
  {
    "chunk_id": "manual_006",
    "section": "第5章: バックエンドの役割",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "アプリ構成",
      "area": "バックエンド",
      "tags": ["バックエンド", "API", "RAG検索", "LLM呼び出し", "データ管理"]
    },
    "content": "バックエンドは裏側で処理を行う領域です。RAG検索、LLM呼び出し、データ管理などを担当します。【章末クイズ】Q1: バックエンドで実行される処理を2つ挙げてください。"
  },
  {
    "chunk_id": "manual_007",
    "section": "第6章: アプリ全体構成の理解",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "アプリ構成",
      "area": "全体構成",
      "tags": ["フロントエンド", "バックエンド", "RAG", "LLM", "システム構成", "連携"]
    },
    "content": "本アプリはフロントエンド、バックエンド、RAG、LLMで構成されます。各要素が連携して質問応答やクイズ判定を実現します。【章末クイズ】Q1: このアプリの主要構成要素を列挙してください。"
  },
  {
    "chunk_id": "manual_008",
    "section": "第7章: Embeddingと意味検索",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "検索",
      "tags": ["Embedding", "ベクトル", "意味検索", "類似度", "数値変換"]
    },
    "content": "Embeddingは文章を数値ベクトルへ変換する技術です。意味的類似度に基づく検索を可能にします。テキストをベクトル空間に配置することで、キーワードの完全一致ではなく、意味的に近い文章を見つけることができます。【章末クイズ】Q1: Embeddingの目的は何ですか？"
  },
  {
    "chunk_id": "manual_009",
    "section": "第8章: ベクトルDBの役割",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "データベース",
      "tags": ["ベクトルDB", "ChromaDB", "類似検索", "Embedding保存"]
    },
    "content": "ベクトルDBはEmbeddingを保存し、類似検索を行うための専用データベースです。通常のRDBではベクトル間の距離計算が困難ですが、ベクトルDBは高速な類似度検索に最適化されています。RAGにおいて、質問文のEmbeddingと最も近い文書を検索する中核的な役割を担います。【章末クイズ】Q1: なぜ通常のDBではなくベクトルDBを使うのですか？"
  },
  {
    "chunk_id": "manual_010",
    "section": "第9章: 検索精度の重要性",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "検索",
      "tags": ["検索精度", "RAG品質", "チャンク", "前処理", "品質依存"]
    },
    "content": "RAGの品質は検索品質に大きく依存します。検索精度が低いと、LLMに無関係な文書が渡され、的外れな回答や誤情報が生成される原因になります。検索精度を高めるためには、チャンク分割の粒度、テキスト前処理の品質、Embeddingモデルの選定が重要です。【章末クイズ】Q1: 検索精度が悪いと何が起きますか？"
  },
  {
    "chunk_id": "manual_011",
    "section": "第10章: OCRと前処理",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "データ前処理",
      "tags": ["OCR", "PDF", "テキスト抽出", "前処理", "誤認識", "正規化"]
    },
    "content": "OCRは画像やPDFからテキストを抽出する技術です。スキャンされた文書やパンフレットなど、テキストデータが直接取得できない資料をRAGに取り込むために使用します。ただし、OCRの誤認識はRAG精度に直接影響します。抽出後のテキスト正規化（不要な改行削除、空白整理、文字統一）が品質を左右します。【章末クイズ】Q1: OCR精度が低いと何が問題になりますか？"
  },
  {
    "chunk_id": "manual_012",
    "section": "第11章: プロンプト設計",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "プロンプト",
      "tags": ["プロンプト", "LLM", "指示文", "文脈", "制約", "役割指定"]
    },
    "content": "プロンプトはLLMへの指示文です。RAGでは、検索で取得した文脈情報をプロンプトに埋め込み、LLMに回答を生成させます。良いプロンプトには、文脈（参照すべき情報）、制約（回答範囲やフォーマット）、役割指定（LLMの振る舞い）の3要素が重要です。【章末クイズ】Q1: 良いRAGプロンプトの要素を挙げてください。"
  },
  {
    "chunk_id": "manual_013",
    "section": "第12章: ハルシネーション対策",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "技術詳細",
      "area": "品質管理",
      "tags": ["ハルシネーション", "誤情報", "対策", "RAG", "制約", "回答拒否"]
    },
    "content": "ハルシネーションとは、LLMが事実に基づかない情報をもっともらしく生成してしまう現象です。LLMは確率的に文章を生成するため、学習データにない情報を「でっちあげる」ことがあります。対策として、RAGによる外部知識の参照、プロンプトでの制約設定、根拠がない場合の回答拒否設計が有効です。【章末クイズ】Q1: ハルシネーションとは何ですか？"
  },
  {
    "chunk_id": "manual_014",
    "section": "第13章: まとめと理解確認",
    "metadata": {
      "source": "RAG_AI_Manual.pdf",
      "category": "まとめ",
      "area": "全般",
      "tags": ["まとめ", "理解確認", "総復習", "構成説明"]
    },
    "content": "本書ではAI、RAG、検索、ベクトルDB、OCR、アプリ構成について学びました。最終的なゴールは「仕組みを説明できること」です。各技術が単独で存在するのではなく、フロントエンド→バックエンド→RAG検索→LLM生成という一連の流れとして連携していることを理解してください。【章末クイズ】Q1: RAGの流れを説明してください。Q2: このアプリの構成を説明してください。"
  }
]
